{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Furthur Finetuning LightGBM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes include:\n",
    "\n",
    "(1) Shifted tuning goal from F-1 score to precision\n",
    "\n",
    "(2) Changed parameter search method from grid search to Bayesian Optimization for broader, more flexible parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_precision_scores = {}\n",
    "\n",
    "import optuna\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Ensure data types are float32 to reduce memory usage\n",
    "X_train_bal = X_train_bal.astype(np.float32)\n",
    "X_test_bal = X_test_bal.astype(np.float32)\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 7, 127),\n",
    "        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 0.5),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 0.5),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 100),\n",
    "        'random_state': 42,\n",
    "        'device': 'gpu',\n",
    "        'gpu_device_id': 0,\n",
    "        'n_jobs': 1,\n",
    "        'verbose': -1\n",
    "    }\n",
    "    clf = LGBMClassifier(**param)\n",
    "    return cross_val_score(clf, X_train_bal, y_train_bal, cv=2, scoring='precision_weighted', n_jobs=1).mean()\n",
    "\n",
    "# Create and run Optuna study\n",
    "study = optuna.create_study(direction='maximize', study_name='LGBM Precision Optimization')\n",
    "study.optimize(objective, n_trials=100, timeout=36000)\n",
    "\n",
    "# Output the best parameters found\n",
    "print(\"\\nBest Parameters found:\", study.best_params)\n",
    "\n",
    "# Train the best model\n",
    "best_model = LGBMClassifier(\n",
    "    **study.best_params,\n",
    "    random_state=42,\n",
    "    device='gpu',\n",
    "    gpu_device_id=0,\n",
    "    n_jobs=1,\n",
    "    verbose=-1\n",
    ")\n",
    "best_model.fit(X_train_bal, y_train_bal)\n",
    "y_pred = best_model.predict(X_test_bal)\n",
    "\n",
    "# Convert labels back to original strings\n",
    "y_test_labels = label_encoder.inverse_transform(y_test_bal)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nLightGBM Classification Report:\")\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n",
    "\n",
    "# Save the classification report as a dictionary\n",
    "precision_scores_lgb = classification_report(y_test_labels, y_pred_labels, output_dict=True)\n",
    "model_precision_scores['LightGBM'] = precision_scores_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters found: {\n",
    "    'colsample_bytree': 0.7715490096744506,\n",
    "    'learning_rate': 0.09741465956967921,\n",
    "    'max_depth': 9,\n",
    "    'min_child_samples': 37,\n",
    "    'n_estimators': 169,\n",
    "    'num_leaves': 90,\n",
    "    'reg_alpha': 0.09536592999298432,\n",
    "    'reg_lambda': 0.3981311006973933,\n",
    "    'subsample': 0.946224464192131,\n",
    "    'random_state': 42,\n",
    "    'device': 'gpu',\n",
    "    'gpu_device_id': 0,\n",
    "    'n_jobs': 1,\n",
    "    'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train LightGBM based on optimal parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best parameters from previous optimization\n",
    "best_params = {\n",
    "    'colsample_bytree': 0.7715490096744506,\n",
    "    'learning_rate': 0.09741465956967921,\n",
    "    'max_depth': 9,\n",
    "    'min_child_samples': 37,\n",
    "    'n_estimators': 169,\n",
    "    'num_leaves': 90,\n",
    "    'reg_alpha': 0.09536592999298432,\n",
    "    'reg_lambda': 0.3981311006973933,\n",
    "    'subsample': 0.946224464192131,\n",
    "    'random_state': 42,\n",
    "    'device': 'gpu',\n",
    "    'gpu_device_id': 0,\n",
    "    'n_jobs': 1,\n",
    "    'verbose': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Ensure data types are float32 to reduce memory usage\n",
    "X_train_bal = X_train_bal.astype(np.float32)\n",
    "X_test_bal = X_test_bal.astype(np.float32)\n",
    "\n",
    "# Train the model using the best parameters\n",
    "model = LGBMClassifier(**best_params)\n",
    "model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = model.predict_proba(X_test_bal)\n",
    "\n",
    "# Encode labels if needed for consistent indexing\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_bal_encoded = label_encoder.fit_transform(y_test_bal)\n",
    "label_names = label_encoder.inverse_transform(np.unique(y_test_bal_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded label 0 corresponds to OTHER\n",
      "Encoded label 1 corresponds to add_license OR remove_license\n",
      "Encoded label 2 corresponds to add_user OR remove_user\n",
      "Encoded label 3 corresponds to add_user_to_channel OR remove_user_from_channel\n",
      "Encoded label 4 corresponds to os_update\n",
      "Encoded label 5 corresponds to password_reset\n",
      "Encoded label 6 corresponds to reset_mfa\n",
      "Encoded label 7 corresponds to shipping_request\n"
     ]
    }
   ],
   "source": [
    "# Manually create label_map\n",
    "label_map = {\n",
    "    0: \"OTHER\",\n",
    "    1: \"add_license OR remove_license\",\n",
    "    2: \"add_user OR remove_user\",\n",
    "    3: \"add_user_to_channel OR remove_user_from_channel\",\n",
    "    4: \"os_update\",\n",
    "    5: \"password_reset\",\n",
    "    6: \"reset_mfa\",\n",
    "    7: \"shipping_request\"\n",
    "}\n",
    "\n",
    "# Print label_map to verify correctness\n",
    "for index, label_name in label_map.items():\n",
    "    print(f\"Encoded label {index} corresponds to {label_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "precision = precision_score(y_test_bal_encoded, y_pred, average=None)\n",
    "recall = recall_score(y_test_bal_encoded, y_pred, average=None)\n",
    "\n",
    "# Store precision and recall results per label\n",
    "precision_recall_results = []\n",
    "for label, name in label_map.items():\n",
    "    precision_recall_results.append({\"Label\": name, \"Metric\": \"Precision\", \"Score\": precision[label]})\n",
    "    precision_recall_results.append({\"Label\": name, \"Metric\": \"Recall\", \"Score\": recall[label]})\n",
    "\n",
    "# Calculate overall precision and recall\n",
    "overall_precision = precision_score(y_test_bal_encoded, y_pred, average=\"macro\")\n",
    "overall_recall = recall_score(y_test_bal_encoded, y_pred, average=\"macro\")\n",
    "precision_recall_results.append({\"Label\": \"Overall\", \"Metric\": \"Precision\", \"Score\": overall_precision})\n",
    "precision_recall_results.append({\"Label\": \"Overall\", \"Metric\": \"Recall\", \"Score\": overall_recall})\n",
    "weighted_recall = recall_score(y_test_bal_encoded, y_pred, average=\"weighted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
